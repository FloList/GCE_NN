{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "gce_nn_example_notebook.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KzCr5LXMjBO"
   },
   "source": [
    "## Tutorial notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This Jupyter notebook shows how to perform a basic analysis of Î³-ray photon-count maps using the convolutional neural network-based method presented in [arXiv:2107.09070](http://arxiv.org/abs/2107.09070). \n",
    "\n",
    "In this example, the photon-count maps consist of **three** different emission components:    \n",
    "1. *Fermi* bubbles (Poissonian)\n",
    "2. Galactic Center Excess (point source-like, single population)\n",
    "3. Isotropic point sources (point source-like, two populations in each map).\n",
    "\n",
    "As discussed in the paper, for the point source-like templates the Poissonian case is included as the limit of ultra-faint point source emission (<< 1 photon expected per source) where the neural network can no longer distinguish point sources from Poissonian emission.\n",
    "\n",
    "To consider different scenarios (e.g. other templates, more training data, different network architectures, etc.), simply modify the sample parameter file ```GCE_NN/parameter_files/parameters.py``` accordingly.\n",
    "The available templates can be viewed in the function ```get_templates()``` in ```GCE/data_utils.py```.\n",
    "\n",
    "Also, if you don't have access to a GPU and just want to try out the code, it is recommended to reduce the number of training steps in the ```parameters.py```\n",
    "file in the folder ```parameter_files``` under \"Training settings\" from ```2500``` to e.g. ```p_train['num_steps'] = 500``` to reduce the\n",
    "training time. In this case, you will see a warning\n",
    "```\n",
    "\"WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`...\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VLj9BMSPMF9V",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "da87b8d4-a5c5-4c2b-c51f-e493dc7dbe2f",
    "ExecuteTime": {
     "end_time": "2023-08-01T08:43:43.998243356Z",
     "start_time": "2023-08-01T08:43:42.599339036Z"
    }
   },
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "import os"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KIx_p5alYlU5",
    "outputId": "18e4bbe0-da02-410c-89f8-6efb72116610",
    "ExecuteTime": {
     "end_time": "2023-08-01T08:43:47.357283656Z",
     "start_time": "2023-08-01T08:43:43.552633788Z"
    }
   },
   "source": [
    "%pip list | grep gce-nn   # check if gce-nn module is there\n",
    "import GCE.gce"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bE7XSJ7rOjgo"
   },
   "source": [
    "First, we need to **initialize** an analysis object."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21lsX63-OjNU",
    "outputId": "8abe98d5-54b6-4426-f5f5-b121668b95c2",
    "is_executing": true
   },
   "source": [
    "gce = GCE.gce.Analysis()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfeV5afmO7pp"
   },
   "source": [
    "Now, let's **load the parameters** from the parameter file in the parameter_files folder."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4hC6e-jZPA-m",
    "outputId": "267d80b0-684a-49fb-c272-787d7dff7d02",
    "is_executing": true
   },
   "source": [
    "gce.load_params(\"../parameter_files/parameters_redo.py\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOpAIsRrdfZB"
   },
   "source": [
    "We can take a look at the loaded parameters:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zfC6OAjPdknM",
    "outputId": "dea66d4d-f70e-431b-e3cc-b7ec974f19d6",
    "is_executing": true
   },
   "source": [
    "gce.print_params()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_LGGzbjeKZH"
   },
   "source": [
    "The parameters are stored in gce.p and can also be accessed group-wise. For example, the Poissonian (P) and point-source (PS) templates used in this analysis can be viewed with"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LZeVTwPveJjS",
    "outputId": "3f467553-faa5-4cb5-b074-a68206dce210",
    "is_executing": true
   },
   "source": [
    "gce.p.mod"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDqev5FQemIK"
   },
   "source": [
    "and the data-related settings (such as the exposure map, the mask for the region of interest, as well as whether the *Fermi* point-spread function at 2 GeV shall be applied) are stored in"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9deORIGwe3G8",
    "outputId": "1c8a99fd-1796-43cc-dd12-2cff027c928b",
    "is_executing": true
   },
   "source": [
    "gce.p.data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRIVxF75dQJh"
   },
   "source": [
    "Now, let's generate some simulated Monte Carlo photon-count maps for each of the templates. The relevant parameters are stored in the field \"tt\" (training and testing data) - most importantly the priors, as well as the number of maps given by \"n_chunk\" (each chunk will be saved in a single file) times the number of simulations per chunk."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j1wpn081dMHD",
    "outputId": "bfbdd9c5-1090-4e80-b80b-80d011fbcd87",
    "is_executing": true
   },
   "source": [
    "gce.p.tt"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6esqIeBWhaDe"
   },
   "source": [
    "To **generate** the template maps, we can simply run"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kgvxgXvmh-3H",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4fe4ee61-73c5-4f53-ae3d-b1682c1f7e32",
    "is_executing": true
   },
   "source": [
    "# Ray settings (for parallelized data generation)\n",
    "# ray_settings = {\"num_cpus\": 4, \"object_store_memory\": 2000000000}\n",
    "# ray_settings = {\"num_cpus\": 4}  # select the number of CPUs here\n",
    "# gce.generate_template_maps(ray_settings, n_example_plots=5, job_id=0)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgSUGOmXJ4Dl"
   },
   "source": [
    "Some example maps (whose number is determined by ```n_example_plots``` above) for each template can be viewed in the folder ```GCE_NN/data/Template_maps/Example_128```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZy9C4Cez6Pu"
   },
   "source": [
    "The next step is to **combine** (i.e. sum up) the individual template maps to obtain the final training, validation, and testing maps. Internally, this is done in two steps: 1) the filenames of the template maps for each of these three subsets are stored in a file, and 2) the template maps are combined and saved."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jv3KUnRmzynd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "98d2f596-716e-4eb6-ea53-9cc425d3ee53",
    "is_executing": true
   },
   "source": [
    "# gce.combine_template_maps(save_filenames=True, do_combine=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfprvUAl2uKc"
   },
   "source": [
    "NOTE: if data has already been generated, the corresponding parameters can be directly loaded from the template maps / combined maps folders, e.g.\n",
    "\n",
    "```\n",
    "gce.load_params(\"../data/Template_maps/Test_128\")\n",
    "gce.load_params(\"../data/Combined_maps/Test_comb_128\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFUd4HLV1uUV"
   },
   "source": [
    "Next, we need to build the **data processing pipeline** that will feed the combined photon-count maps to the neural network."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oY_3_oH71mmS",
    "outputId": "18a863f3-c50a-4a2d-fa22-500b56d9fbd4",
    "is_executing": true
   },
   "source": [
    "gce.build_pipeline()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0t-F3xFZMb3V"
   },
   "source": [
    "We can use the method ```get_samples()``` to get photon-count maps and their associated labels from the datasets **train** (used for training), **val** (used as an independent validation dataset during training), and **test** (used for testing once the training is finished) "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NCq1omWZ2_5y",
    "outputId": "6cded615-f41b-4fb9-ec81-624b587e051f",
    "is_executing": true
   },
   "source": [
    "samples = gce.datasets[\"test\"].get_samples(1)\n",
    "data, labels = samples[\"data\"], samples[\"label\"]  # samples contains data and labels (flux fractions & SCD histograms)\n",
    "print(\"Shapes:\")\n",
    "print(\"  Data\", data.shape)  # n_samples x n_pix_in_ROI\n",
    "print(\"  Flux fractions\", labels[0].shape)  # n_samples x n_templates\n",
    "print(\"  SCD histograms\", labels[1].shape)  # n_samples x n_bins x n_PS_templates"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtAvpwmg2FCs"
   },
   "source": [
    "Let's take a look at a combined map. The maps are compressed and only contain the pixels that lie within the ROI - the method ```decompress()``` returns the full-sky map that can be fed to the healpy functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suiTYvwM32ll"
   },
   "source": [
    "We will plot \n",
    "1. the **photon-count map**, \n",
    "2. the rescaled version in **'flux' space** as shown to the neural network (divided by exposure correction), and \n",
    "3. the *Fermi* **exposure correction**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# NOTE: the maps are stored in NEST format\n",
    "map_to_plot = 0\n",
    "r = gce.p.data[\"outer_rad\"] + 1\n",
    "hp.cartview(gce.decompress(data[map_to_plot] * gce.template_dict[\"rescale_compressed\"]), nest=True,\n",
    "            title=\"Simulated data: Count space\", lonra=[-r, r], latra=[-r, r])\n",
    "hp.cartview(gce.decompress(data[map_to_plot]), nest=True,\n",
    "            title=\"Simulated data: Flux space\", lonra=[-r, r], latra=[-r, r])\n",
    "hp.cartview(gce.decompress(gce.template_dict[\"rescale_compressed\"], fill_value=np.nan), nest=True,\n",
    "            title=\"Fermi exposure correction\", lonra=[-r, r], latra=[-r, r])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "is_executing": true
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZdi-sqRRkOS"
   },
   "source": [
    "Let's also plot the real *Fermi* map in our region of interest. Of course, it looks quite different from our simulated maps because we only included the *Fermi* bubbles, the GCE, and isotropic point sources in this example (so we are completely ignoring the diffuse Galactic foregrounds, which are responsible for the majority of photon counts)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "xQb4l2YTQVy1",
    "outputId": "49da64e5-eb55-4b7a-d7ef-a6e10778a3f6",
    "is_executing": true
   },
   "source": [
    "fermi_counts = gce.datasets[\"test\"].get_fermi_counts()\n",
    "hp.cartview(gce.decompress(fermi_counts * gce.generators[\"test\"].settings_dict[\"rescale_compressed\"]), nest=True,\n",
    "            title=\"Fermi data: Count space\", max=100, lonra=[-r, r], latra=[-r, r])\n",
    "# hp.cartview(gce.decompress(fermi_counts), nest=True, title=\"Fermi data: Flux space\", max=100)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSlNFiUVT7m7"
   },
   "source": [
    "Now, it's time to **build** our neural network:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gce.build_nn()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "is_executing": true
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgTUkgH9UG-j"
   },
   "source": [
    "*NOTE*: Once the neural network has been trained, **loading** is as easy as ```gce.load_nn()```."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eg7I_lFQhFek",
    "is_executing": true
   },
   "source": [
    "# gce.load_nn()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fpRCAyIUWxm"
   },
   "source": [
    "Let's **train** our neural network to predict \n",
    "1. the **flux fractions** of the different templates (using a negative maximum log-likelihood loss function), and \n",
    "2. the **SCD histograms** of the GCE and isotropic point source populations (using the *Earth Mover's pinball loss*, see [arXiv:2106.02051](https://arxiv.org/abs/2106.02051))."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7GFC2rqsUVa_",
    "outputId": "4da7e2e5-d228-4d81-d24f-2f58659e9278",
    "is_executing": true
   },
   "source": [
    "# gce.train_nn(\"flux_fractions\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eiDLtxMkUuxB",
    "outputId": "172388a8-828b-4a17-99b7-502723681801",
    "is_executing": true
   },
   "source": [
    "gce.train_nn(\"histograms\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBibNbv-U6GA"
   },
   "source": [
    "Finally, let's **evaluate** the performance of our neural network on simulated test data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "r7wRxSZ_VFU_",
    "is_executing": true
   },
   "source": [
    "n_samples = 20\n",
    "test_samples = gce.datasets[\"test\"].get_samples(n_samples)\n",
    "test_data, test_ffs, test_hists = test_samples[\"data\"], test_samples[\"label\"][0], test_samples[\"label\"][1]\n",
    "tau = np.arange(5, 100, 5) * 0.01  # quantile levels for SCD histograms, from 5% to 95% in steps of 5%\n",
    "pred = gce.predict(test_data, tau=tau, multiple_taus=True)  # get the NN predictions"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bbWYHid2VUJs",
    "outputId": "94fbe736-af3b-402e-c5e0-8643d27be654",
    "is_executing": true
   },
   "source": [
    "# Make some plots (will be saved in the models folder)\n",
    "gce.plot_nn_architecture()\n",
    "gce.plot_flux_fractions(test_ffs, pred)\n",
    "gce.plot_histograms(test_hists, pred, plot_inds=np.arange(9))\n",
    "gce.plot_maps(test_data, decompress=True, plot_inds=np.arange(9))\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BnWAJt1Tf0j",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Clearly, the training dataset is too small and the training was too short to obtain accurate and precise predictions. Still, the neural networks have already learned *something*, and the predictions are roughly in the right ballpark."
   ]
  }
 ]
}
